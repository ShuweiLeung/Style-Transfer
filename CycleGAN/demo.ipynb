{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, pickle, argparse, network, utils, itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import test\n",
    "import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', required=False, default='apple2orange',  help='the name of train set')\n",
    "parser.add_argument('--train_subfolder', required=False, default='train',  help='the subfolder name of train set')\n",
    "parser.add_argument('--test_subfolder', required=False, default='test',  help='the subfolder name of test set')\n",
    "parser.add_argument('--input_ngc', type=int, default=3, help='number of input channel for generator')\n",
    "parser.add_argument('--output_ngc', type=int, default=3, help='number of output channel for generator')\n",
    "parser.add_argument('--input_ndc', type=int, default=3, help='number of input channel for discriminator')\n",
    "parser.add_argument('--output_ndc', type=int, default=1, help='number of output channel for discriminator')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='batch size')\n",
    "parser.add_argument('--ngf', type=int, default=32)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--nb', type=int, default=9, help='the number of resnet block layer for generator')\n",
    "parser.add_argument('--input_size', type=int, default=256, help='input size')\n",
    "parser.add_argument('--resize_scale', type=int, default=286, help='resize scale (0 is false)')\n",
    "parser.add_argument('--crop', type=bool, default=True, help='random crop True or False')\n",
    "parser.add_argument('--fliplr', type=bool, default=True, help='random fliplr True or False')\n",
    "parser.add_argument('--train_epoch', type=int, default=200, help='train epochs num')\n",
    "parser.add_argument('--decay_epoch', type=int, default=100, help='learning rate decay start epoch num')\n",
    "parser.add_argument('--lrD', type=float, default=0.0002, help='learning rate for discriminator')\n",
    "parser.add_argument('--lrG', type=float, default=0.0002, help='learning rate for generator')\n",
    "parser.add_argument('--lambdaA', type=float, default=10, help='lambdaA for cycle loss')\n",
    "parser.add_argument('--lambdaB', type=float, default=10, help='lambdaB for cycle loss')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for Adam optimizer')\n",
    "parser.add_argument('--beta2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
    "parser.add_argument('--save_root', required=False, default='results', help='results save path')\n",
    "parser.add_argument('--cuda', type=bool, default=True, help='use GPU computation')\n",
    "opt = parser.parse_args(args=['--dataset', 'facades'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Arguments -------------\n",
      "batch_size = 1\n",
      "beta1 = 0.5\n",
      "beta2 = 0.999\n",
      "crop = True\n",
      "cuda = True\n",
      "dataset = facades\n",
      "decay_epoch = 100\n",
      "fliplr = True\n",
      "input_ndc = 3\n",
      "input_ngc = 3\n",
      "input_size = 256\n",
      "lambdaA = 10\n",
      "lambdaB = 10\n",
      "lrD = 0.0002\n",
      "lrG = 0.0002\n",
      "nb = 9\n",
      "ndf = 64\n",
      "ngf = 32\n",
      "output_ndc = 1\n",
      "output_ngc = 3\n",
      "resize_scale = 286\n",
      "save_root = results\n",
      "test_subfolder = test\n",
      "train_epoch = 200\n",
      "train_subfolder = train\n",
      "-------------- End ----------------\n"
     ]
    }
   ],
   "source": [
    "print('------------ Arguments -------------')\n",
    "for k, v in sorted(vars(opt).items()):\n",
    "    print('%s = %s' % (str(k), str(v)))\n",
    "print('-------------- End ----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results save path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root, model = utils.filepath_check_and_initialize(opt.dataset, opt.save_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "train_loader_A = utils.data_load('data/' + opt.dataset, opt.train_subfolder + 'A', transform, opt.batch_size, shuffle=True)\n",
    "train_loader_B = utils.data_load('data/' + opt.dataset, opt.train_subfolder + 'B', transform, opt.batch_size, shuffle=True)\n",
    "test_loader_A = utils.data_load('data/' + opt.dataset, opt.test_subfolder + 'A', transform, opt.batch_size, shuffle=False)\n",
    "test_loader_B = utils.data_load('data/' + opt.dataset, opt.test_subfolder + 'B', transform, opt.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize generators and discriminators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_A, G_B = network.initialize_generators(opt.input_ngc, opt.output_ngc, opt.ngf, opt.nb, opt.cuda)\n",
    "D_A, D_B = network.initialize_discriminators(opt.input_ndc, opt.output_ndc, opt.ndf, opt.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialized Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generator(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (conv1_norm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2_norm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv3_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (resnet_blocks): Sequential(\n",
      "    (0): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (1): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (2): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (3): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (4): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (5): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (6): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (7): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (8): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "  )\n",
      "  (deconv1): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (deconv1_norm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (deconv2): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (deconv2_norm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (deconv3): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      ")\n",
      "Total number of parameters in net is 2850563\n",
      "generator(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (conv1_norm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2_norm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv3_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (resnet_blocks): Sequential(\n",
      "    (0): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (1): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (2): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (3): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (4): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (5): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (6): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (7): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (8): resnet_block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "  )\n",
      "  (deconv1): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (deconv1_norm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (deconv2): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  (deconv2_norm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (deconv3): Conv2d(32, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      ")\n",
      "Total number of parameters in net is 2850563\n",
      "discriminator(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv3_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (conv4): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (conv5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Total number of parameters in net is 2764737\n",
      "discriminator(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2_norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv3_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (conv4): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (conv5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "Total number of parameters in net is 2764737\n"
     ]
    }
   ],
   "source": [
    "utils.print_network(G_A)\n",
    "utils.print_network(G_B)\n",
    "utils.print_network(D_A)\n",
    "utils.print_network(D_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE_loss = nn.BCELoss().cuda()\n",
    "MSE_loss = nn.MSELoss().cuda()\n",
    "L1_loss = nn.L1Loss().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_optimizer = optim.Adam(itertools.chain(G_A.parameters(), G_B.parameters()), lr=opt.lrG, betas=(opt.beta1, opt.beta2))\n",
    "D_A_optimizer = optim.Adam(D_A.parameters(), lr=opt.lrD, betas=(opt.beta1, opt.beta2))\n",
    "D_B_optimizer = optim.Adam(D_B.parameters(), lr=opt.lrD, betas=(opt.beta1, opt.beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeA_store = utils.ImagePool(50)\n",
    "fakeB_store = utils.ImagePool(50)\n",
    "\n",
    "train_hist = utils.train_histogram_initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************start training!**************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/200] - ptime: 160.26, loss_D_A: 0.428, loss_D_B: 0.420, loss_G_A: 0.566, loss_G_B: 0.536, loss_A_cycle: 2.496, loss_B_cycle: 2.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/home-02/52/552/s1liang/CycleGAN/train.py:10: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  realA = Variable(realA.cuda(), volatile=True)\n",
      "/datasets/home/home-02/52/552/s1liang/CycleGAN/train.py:26: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  realB = Variable(realB.cuda(), volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/200] - ptime: 159.58, loss_D_A: 0.250, loss_D_B: 0.248, loss_G_A: 0.462, loss_G_B: 0.464, loss_A_cycle: 2.191, loss_B_cycle: 1.554\n",
      "[3/200] - ptime: 159.49, loss_D_A: 0.221, loss_D_B: 0.228, loss_G_A: 0.465, loss_G_B: 0.464, loss_A_cycle: 2.140, loss_B_cycle: 1.454\n",
      "[4/200] - ptime: 159.79, loss_D_A: 0.219, loss_D_B: 0.220, loss_G_A: 0.484, loss_G_B: 0.452, loss_A_cycle: 1.996, loss_B_cycle: 1.215\n",
      "[5/200] - ptime: 159.46, loss_D_A: 0.209, loss_D_B: 0.197, loss_G_A: 0.517, loss_G_B: 0.512, loss_A_cycle: 2.057, loss_B_cycle: 1.336\n",
      "[6/200] - ptime: 160.16, loss_D_A: 0.196, loss_D_B: 0.173, loss_G_A: 0.529, loss_G_B: 0.512, loss_A_cycle: 1.966, loss_B_cycle: 1.171\n",
      "[7/200] - ptime: 166.18, loss_D_A: 0.206, loss_D_B: 0.176, loss_G_A: 0.526, loss_G_B: 0.494, loss_A_cycle: 1.921, loss_B_cycle: 1.110\n",
      "[8/200] - ptime: 159.77, loss_D_A: 0.179, loss_D_B: 0.170, loss_G_A: 0.548, loss_G_B: 0.484, loss_A_cycle: 1.931, loss_B_cycle: 1.119\n",
      "[9/200] - ptime: 159.86, loss_D_A: 0.178, loss_D_B: 0.182, loss_G_A: 0.558, loss_G_B: 0.479, loss_A_cycle: 1.848, loss_B_cycle: 1.014\n",
      "[10/200] - ptime: 159.78, loss_D_A: 0.160, loss_D_B: 0.166, loss_G_A: 0.580, loss_G_B: 0.529, loss_A_cycle: 1.934, loss_B_cycle: 1.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/home-02/52/552/s1liang/CycleGAN/test.py:11: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  realA = Variable(realA.cuda(), volatile=True)\n",
      "/datasets/home/home-02/52/552/s1liang/CycleGAN/test.py:25: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  realB = Variable(realB.cuda(), volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/200] - ptime: 159.56, loss_D_A: 0.153, loss_D_B: 0.166, loss_G_A: 0.605, loss_G_B: 0.510, loss_A_cycle: 1.860, loss_B_cycle: 1.018\n",
      "[12/200] - ptime: 159.58, loss_D_A: 0.152, loss_D_B: 0.159, loss_G_A: 0.588, loss_G_B: 0.499, loss_A_cycle: 1.815, loss_B_cycle: 0.971\n",
      "[13/200] - ptime: 159.58, loss_D_A: 0.157, loss_D_B: 0.161, loss_G_A: 0.612, loss_G_B: 0.494, loss_A_cycle: 1.809, loss_B_cycle: 0.941\n",
      "[14/200] - ptime: 159.75, loss_D_A: 0.156, loss_D_B: 0.157, loss_G_A: 0.586, loss_G_B: 0.478, loss_A_cycle: 1.823, loss_B_cycle: 0.911\n",
      "[15/200] - ptime: 159.57, loss_D_A: 0.134, loss_D_B: 0.145, loss_G_A: 0.612, loss_G_B: 0.501, loss_A_cycle: 1.771, loss_B_cycle: 0.899\n",
      "[16/200] - ptime: 159.86, loss_D_A: 0.132, loss_D_B: 0.134, loss_G_A: 0.616, loss_G_B: 0.524, loss_A_cycle: 1.836, loss_B_cycle: 0.999\n",
      "[17/200] - ptime: 159.54, loss_D_A: 0.140, loss_D_B: 0.147, loss_G_A: 0.606, loss_G_B: 0.484, loss_A_cycle: 1.712, loss_B_cycle: 0.839\n",
      "[18/200] - ptime: 158.87, loss_D_A: 0.133, loss_D_B: 0.136, loss_G_A: 0.611, loss_G_B: 0.523, loss_A_cycle: 1.752, loss_B_cycle: 0.878\n",
      "[19/200] - ptime: 159.79, loss_D_A: 0.135, loss_D_B: 0.131, loss_G_A: 0.619, loss_G_B: 0.523, loss_A_cycle: 1.703, loss_B_cycle: 0.848\n",
      "[20/200] - ptime: 160.08, loss_D_A: 0.126, loss_D_B: 0.119, loss_G_A: 0.642, loss_G_B: 0.549, loss_A_cycle: 1.688, loss_B_cycle: 0.867\n",
      "[21/200] - ptime: 159.38, loss_D_A: 0.125, loss_D_B: 0.120, loss_G_A: 0.641, loss_G_B: 0.551, loss_A_cycle: 1.732, loss_B_cycle: 0.921\n",
      "[22/200] - ptime: 160.17, loss_D_A: 0.130, loss_D_B: 0.123, loss_G_A: 0.641, loss_G_B: 0.521, loss_A_cycle: 1.717, loss_B_cycle: 0.893\n",
      "[23/200] - ptime: 159.87, loss_D_A: 0.130, loss_D_B: 0.141, loss_G_A: 0.620, loss_G_B: 0.490, loss_A_cycle: 1.607, loss_B_cycle: 0.767\n",
      "[24/200] - ptime: 160.98, loss_D_A: 0.119, loss_D_B: 0.128, loss_G_A: 0.635, loss_G_B: 0.538, loss_A_cycle: 1.628, loss_B_cycle: 0.762\n",
      "[25/200] - ptime: 159.61, loss_D_A: 0.110, loss_D_B: 0.128, loss_G_A: 0.660, loss_G_B: 0.550, loss_A_cycle: 1.640, loss_B_cycle: 0.794\n",
      "[26/200] - ptime: 160.08, loss_D_A: 0.110, loss_D_B: 0.125, loss_G_A: 0.653, loss_G_B: 0.517, loss_A_cycle: 1.598, loss_B_cycle: 0.741\n",
      "[27/200] - ptime: 159.56, loss_D_A: 0.115, loss_D_B: 0.133, loss_G_A: 0.643, loss_G_B: 0.515, loss_A_cycle: 1.612, loss_B_cycle: 0.766\n",
      "[28/200] - ptime: 159.79, loss_D_A: 0.125, loss_D_B: 0.138, loss_G_A: 0.642, loss_G_B: 0.516, loss_A_cycle: 1.559, loss_B_cycle: 0.755\n",
      "[29/200] - ptime: 159.59, loss_D_A: 0.112, loss_D_B: 0.126, loss_G_A: 0.647, loss_G_B: 0.525, loss_A_cycle: 1.585, loss_B_cycle: 0.751\n",
      "[30/200] - ptime: 159.68, loss_D_A: 0.103, loss_D_B: 0.124, loss_G_A: 0.679, loss_G_B: 0.550, loss_A_cycle: 1.583, loss_B_cycle: 0.775\n",
      "[31/200] - ptime: 159.72, loss_D_A: 0.114, loss_D_B: 0.138, loss_G_A: 0.652, loss_G_B: 0.505, loss_A_cycle: 1.540, loss_B_cycle: 0.718\n",
      "[32/200] - ptime: 160.35, loss_D_A: 0.109, loss_D_B: 0.121, loss_G_A: 0.667, loss_G_B: 0.556, loss_A_cycle: 1.543, loss_B_cycle: 0.789\n",
      "[33/200] - ptime: 159.57, loss_D_A: 0.102, loss_D_B: 0.120, loss_G_A: 0.685, loss_G_B: 0.543, loss_A_cycle: 1.541, loss_B_cycle: 0.721\n",
      "[34/200] - ptime: 160.07, loss_D_A: 0.098, loss_D_B: 0.124, loss_G_A: 0.698, loss_G_B: 0.528, loss_A_cycle: 1.532, loss_B_cycle: 0.719\n",
      "[35/200] - ptime: 159.57, loss_D_A: 0.100, loss_D_B: 0.122, loss_G_A: 0.701, loss_G_B: 0.533, loss_A_cycle: 1.515, loss_B_cycle: 0.740\n",
      "[36/200] - ptime: 159.78, loss_D_A: 0.093, loss_D_B: 0.118, loss_G_A: 0.691, loss_G_B: 0.572, loss_A_cycle: 1.535, loss_B_cycle: 0.751\n",
      "[37/200] - ptime: 159.98, loss_D_A: 0.098, loss_D_B: 0.114, loss_G_A: 0.693, loss_G_B: 0.560, loss_A_cycle: 1.500, loss_B_cycle: 0.754\n",
      "[38/200] - ptime: 159.79, loss_D_A: 0.098, loss_D_B: 0.126, loss_G_A: 0.694, loss_G_B: 0.509, loss_A_cycle: 1.447, loss_B_cycle: 0.687\n",
      "[39/200] - ptime: 160.25, loss_D_A: 0.094, loss_D_B: 0.128, loss_G_A: 0.711, loss_G_B: 0.538, loss_A_cycle: 1.485, loss_B_cycle: 0.718\n",
      "[40/200] - ptime: 160.37, loss_D_A: 0.091, loss_D_B: 0.122, loss_G_A: 0.698, loss_G_B: 0.521, loss_A_cycle: 1.484, loss_B_cycle: 0.694\n",
      "[41/200] - ptime: 159.99, loss_D_A: 0.092, loss_D_B: 0.120, loss_G_A: 0.687, loss_G_B: 0.538, loss_A_cycle: 1.446, loss_B_cycle: 0.701\n",
      "[42/200] - ptime: 160.23, loss_D_A: 0.091, loss_D_B: 0.122, loss_G_A: 0.706, loss_G_B: 0.538, loss_A_cycle: 1.440, loss_B_cycle: 0.706\n",
      "[43/200] - ptime: 160.15, loss_D_A: 0.091, loss_D_B: 0.130, loss_G_A: 0.712, loss_G_B: 0.523, loss_A_cycle: 1.445, loss_B_cycle: 0.716\n",
      "[44/200] - ptime: 159.99, loss_D_A: 0.086, loss_D_B: 0.115, loss_G_A: 0.715, loss_G_B: 0.563, loss_A_cycle: 1.457, loss_B_cycle: 0.700\n",
      "[45/200] - ptime: 159.89, loss_D_A: 0.091, loss_D_B: 0.121, loss_G_A: 0.713, loss_G_B: 0.529, loss_A_cycle: 1.423, loss_B_cycle: 0.710\n",
      "[46/200] - ptime: 159.98, loss_D_A: 0.089, loss_D_B: 0.125, loss_G_A: 0.693, loss_G_B: 0.519, loss_A_cycle: 1.381, loss_B_cycle: 0.677\n",
      "[47/200] - ptime: 159.97, loss_D_A: 0.092, loss_D_B: 0.130, loss_G_A: 0.713, loss_G_B: 0.516, loss_A_cycle: 1.380, loss_B_cycle: 0.670\n",
      "[48/200] - ptime: 160.07, loss_D_A: 0.088, loss_D_B: 0.126, loss_G_A: 0.714, loss_G_B: 0.516, loss_A_cycle: 1.399, loss_B_cycle: 0.678\n",
      "[49/200] - ptime: 159.80, loss_D_A: 0.084, loss_D_B: 0.126, loss_G_A: 0.714, loss_G_B: 0.540, loss_A_cycle: 1.385, loss_B_cycle: 0.667\n",
      "[50/200] - ptime: 160.27, loss_D_A: 0.081, loss_D_B: 0.126, loss_G_A: 0.710, loss_G_B: 0.542, loss_A_cycle: 1.426, loss_B_cycle: 0.676\n",
      "[51/200] - ptime: 159.98, loss_D_A: 0.081, loss_D_B: 0.120, loss_G_A: 0.739, loss_G_B: 0.565, loss_A_cycle: 1.425, loss_B_cycle: 0.708\n",
      "[52/200] - ptime: 160.00, loss_D_A: 0.084, loss_D_B: 0.120, loss_G_A: 0.733, loss_G_B: 0.544, loss_A_cycle: 1.354, loss_B_cycle: 0.694\n",
      "[53/200] - ptime: 159.90, loss_D_A: 0.091, loss_D_B: 0.124, loss_G_A: 0.698, loss_G_B: 0.554, loss_A_cycle: 1.364, loss_B_cycle: 0.668\n",
      "[54/200] - ptime: 159.77, loss_D_A: 0.079, loss_D_B: 0.125, loss_G_A: 0.734, loss_G_B: 0.539, loss_A_cycle: 1.334, loss_B_cycle: 0.673\n",
      "[55/200] - ptime: 159.47, loss_D_A: 0.074, loss_D_B: 0.108, loss_G_A: 0.734, loss_G_B: 0.579, loss_A_cycle: 1.411, loss_B_cycle: 0.757\n",
      "[56/200] - ptime: 159.89, loss_D_A: 0.074, loss_D_B: 0.122, loss_G_A: 0.751, loss_G_B: 0.538, loss_A_cycle: 1.389, loss_B_cycle: 0.677\n",
      "[57/200] - ptime: 160.00, loss_D_A: 0.075, loss_D_B: 0.125, loss_G_A: 0.731, loss_G_B: 0.526, loss_A_cycle: 1.343, loss_B_cycle: 0.653\n",
      "[58/200] - ptime: 159.66, loss_D_A: 0.080, loss_D_B: 0.111, loss_G_A: 0.736, loss_G_B: 0.592, loss_A_cycle: 1.339, loss_B_cycle: 0.702\n",
      "[59/200] - ptime: 160.48, loss_D_A: 0.080, loss_D_B: 0.118, loss_G_A: 0.721, loss_G_B: 0.543, loss_A_cycle: 1.329, loss_B_cycle: 0.664\n",
      "[60/200] - ptime: 160.18, loss_D_A: 0.078, loss_D_B: 0.120, loss_G_A: 0.761, loss_G_B: 0.526, loss_A_cycle: 1.325, loss_B_cycle: 0.648\n",
      "[61/200] - ptime: 160.37, loss_D_A: 0.077, loss_D_B: 0.124, loss_G_A: 0.736, loss_G_B: 0.500, loss_A_cycle: 1.297, loss_B_cycle: 0.632\n",
      "[62/200] - ptime: 160.17, loss_D_A: 0.079, loss_D_B: 0.127, loss_G_A: 0.729, loss_G_B: 0.493, loss_A_cycle: 1.306, loss_B_cycle: 0.617\n",
      "[63/200] - ptime: 160.17, loss_D_A: 0.077, loss_D_B: 0.118, loss_G_A: 0.750, loss_G_B: 0.523, loss_A_cycle: 1.353, loss_B_cycle: 0.655\n",
      "[64/200] - ptime: 160.19, loss_D_A: 0.074, loss_D_B: 0.115, loss_G_A: 0.766, loss_G_B: 0.553, loss_A_cycle: 1.336, loss_B_cycle: 0.663\n",
      "[65/200] - ptime: 160.37, loss_D_A: 0.069, loss_D_B: 0.114, loss_G_A: 0.781, loss_G_B: 0.555, loss_A_cycle: 1.326, loss_B_cycle: 0.669\n",
      "[66/200] - ptime: 160.47, loss_D_A: 0.075, loss_D_B: 0.124, loss_G_A: 0.750, loss_G_B: 0.518, loss_A_cycle: 1.306, loss_B_cycle: 0.640\n",
      "[67/200] - ptime: 160.11, loss_D_A: 0.077, loss_D_B: 0.123, loss_G_A: 0.764, loss_G_B: 0.495, loss_A_cycle: 1.307, loss_B_cycle: 0.638\n",
      "[68/200] - ptime: 159.96, loss_D_A: 0.076, loss_D_B: 0.121, loss_G_A: 0.742, loss_G_B: 0.533, loss_A_cycle: 1.279, loss_B_cycle: 0.625\n",
      "[69/200] - ptime: 160.28, loss_D_A: 0.070, loss_D_B: 0.111, loss_G_A: 0.743, loss_G_B: 0.536, loss_A_cycle: 1.287, loss_B_cycle: 0.647\n",
      "[70/200] - ptime: 160.56, loss_D_A: 0.077, loss_D_B: 0.115, loss_G_A: 0.741, loss_G_B: 0.516, loss_A_cycle: 1.281, loss_B_cycle: 0.615\n",
      "[71/200] - ptime: 159.76, loss_D_A: 0.067, loss_D_B: 0.115, loss_G_A: 0.759, loss_G_B: 0.552, loss_A_cycle: 1.274, loss_B_cycle: 0.649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72/200] - ptime: 160.38, loss_D_A: 0.077, loss_D_B: 0.122, loss_G_A: 0.757, loss_G_B: 0.516, loss_A_cycle: 1.284, loss_B_cycle: 0.594\n",
      "[73/200] - ptime: 160.58, loss_D_A: 0.074, loss_D_B: 0.121, loss_G_A: 0.755, loss_G_B: 0.514, loss_A_cycle: 1.266, loss_B_cycle: 0.631\n",
      "[74/200] - ptime: 160.39, loss_D_A: 0.074, loss_D_B: 0.127, loss_G_A: 0.743, loss_G_B: 0.523, loss_A_cycle: 1.267, loss_B_cycle: 0.622\n",
      "[75/200] - ptime: 160.58, loss_D_A: 0.064, loss_D_B: 0.119, loss_G_A: 0.774, loss_G_B: 0.543, loss_A_cycle: 1.282, loss_B_cycle: 0.634\n",
      "[76/200] - ptime: 160.26, loss_D_A: 0.069, loss_D_B: 0.117, loss_G_A: 0.742, loss_G_B: 0.522, loss_A_cycle: 1.261, loss_B_cycle: 0.622\n",
      "[77/200] - ptime: 160.32, loss_D_A: 0.072, loss_D_B: 0.126, loss_G_A: 0.764, loss_G_B: 0.511, loss_A_cycle: 1.254, loss_B_cycle: 0.611\n",
      "[78/200] - ptime: 159.97, loss_D_A: 0.066, loss_D_B: 0.119, loss_G_A: 0.780, loss_G_B: 0.540, loss_A_cycle: 1.276, loss_B_cycle: 0.636\n",
      "[79/200] - ptime: 161.17, loss_D_A: 0.060, loss_D_B: 0.105, loss_G_A: 0.812, loss_G_B: 0.591, loss_A_cycle: 1.286, loss_B_cycle: 0.650\n",
      "[80/200] - ptime: 160.17, loss_D_A: 0.071, loss_D_B: 0.118, loss_G_A: 0.771, loss_G_B: 0.512, loss_A_cycle: 1.239, loss_B_cycle: 0.594\n",
      "[81/200] - ptime: 160.38, loss_D_A: 0.071, loss_D_B: 0.121, loss_G_A: 0.748, loss_G_B: 0.528, loss_A_cycle: 1.249, loss_B_cycle: 0.608\n",
      "[82/200] - ptime: 160.09, loss_D_A: 0.068, loss_D_B: 0.125, loss_G_A: 0.778, loss_G_B: 0.522, loss_A_cycle: 1.251, loss_B_cycle: 0.606\n",
      "[83/200] - ptime: 160.30, loss_D_A: 0.060, loss_D_B: 0.114, loss_G_A: 0.796, loss_G_B: 0.511, loss_A_cycle: 1.271, loss_B_cycle: 0.610\n",
      "[84/200] - ptime: 159.87, loss_D_A: 0.069, loss_D_B: 0.123, loss_G_A: 0.747, loss_G_B: 0.485, loss_A_cycle: 1.228, loss_B_cycle: 0.590\n",
      "[85/200] - ptime: 160.38, loss_D_A: 0.067, loss_D_B: 0.126, loss_G_A: 0.772, loss_G_B: 0.509, loss_A_cycle: 1.216, loss_B_cycle: 0.600\n",
      "[86/200] - ptime: 160.36, loss_D_A: 0.065, loss_D_B: 0.122, loss_G_A: 0.772, loss_G_B: 0.519, loss_A_cycle: 1.238, loss_B_cycle: 0.599\n",
      "[87/200] - ptime: 160.01, loss_D_A: 0.073, loss_D_B: 0.116, loss_G_A: 0.760, loss_G_B: 0.537, loss_A_cycle: 1.226, loss_B_cycle: 0.601\n",
      "[88/200] - ptime: 160.26, loss_D_A: 0.071, loss_D_B: 0.118, loss_G_A: 0.766, loss_G_B: 0.525, loss_A_cycle: 1.242, loss_B_cycle: 0.598\n",
      "[89/200] - ptime: 159.89, loss_D_A: 0.057, loss_D_B: 0.120, loss_G_A: 0.769, loss_G_B: 0.509, loss_A_cycle: 1.274, loss_B_cycle: 0.599\n",
      "[90/200] - ptime: 160.36, loss_D_A: 0.066, loss_D_B: 0.117, loss_G_A: 0.789, loss_G_B: 0.556, loss_A_cycle: 1.213, loss_B_cycle: 0.613\n",
      "[91/200] - ptime: 160.47, loss_D_A: 0.061, loss_D_B: 0.111, loss_G_A: 0.751, loss_G_B: 0.529, loss_A_cycle: 1.213, loss_B_cycle: 0.607\n",
      "[92/200] - ptime: 160.22, loss_D_A: 0.064, loss_D_B: 0.118, loss_G_A: 0.791, loss_G_B: 0.524, loss_A_cycle: 1.225, loss_B_cycle: 0.595\n",
      "[93/200] - ptime: 160.29, loss_D_A: 0.064, loss_D_B: 0.127, loss_G_A: 0.790, loss_G_B: 0.508, loss_A_cycle: 1.214, loss_B_cycle: 0.566\n",
      "[94/200] - ptime: 160.08, loss_D_A: 0.061, loss_D_B: 0.126, loss_G_A: 0.785, loss_G_B: 0.489, loss_A_cycle: 1.221, loss_B_cycle: 0.586\n",
      "[95/200] - ptime: 160.58, loss_D_A: 0.058, loss_D_B: 0.122, loss_G_A: 0.765, loss_G_B: 0.531, loss_A_cycle: 1.244, loss_B_cycle: 0.599\n",
      "[96/200] - ptime: 160.38, loss_D_A: 0.064, loss_D_B: 0.127, loss_G_A: 0.760, loss_G_B: 0.507, loss_A_cycle: 1.207, loss_B_cycle: 0.581\n",
      "[97/200] - ptime: 161.07, loss_D_A: 0.061, loss_D_B: 0.114, loss_G_A: 0.785, loss_G_B: 0.528, loss_A_cycle: 1.234, loss_B_cycle: 0.601\n",
      "[98/200] - ptime: 160.75, loss_D_A: 0.061, loss_D_B: 0.120, loss_G_A: 0.793, loss_G_B: 0.521, loss_A_cycle: 1.192, loss_B_cycle: 0.589\n",
      "[99/200] - ptime: 160.29, loss_D_A: 0.069, loss_D_B: 0.112, loss_G_A: 0.784, loss_G_B: 0.543, loss_A_cycle: 1.220, loss_B_cycle: 0.594\n",
      "[100/200] - ptime: 160.38, loss_D_A: 0.059, loss_D_B: 0.116, loss_G_A: 0.799, loss_G_B: 0.557, loss_A_cycle: 1.210, loss_B_cycle: 0.598\n",
      "[101/200] - ptime: 160.18, loss_D_A: 0.058, loss_D_B: 0.110, loss_G_A: 0.788, loss_G_B: 0.527, loss_A_cycle: 1.176, loss_B_cycle: 0.585\n",
      "[102/200] - ptime: 160.47, loss_D_A: 0.059, loss_D_B: 0.110, loss_G_A: 0.777, loss_G_B: 0.551, loss_A_cycle: 1.213, loss_B_cycle: 0.609\n",
      "[103/200] - ptime: 160.29, loss_D_A: 0.055, loss_D_B: 0.113, loss_G_A: 0.787, loss_G_B: 0.546, loss_A_cycle: 1.173, loss_B_cycle: 0.597\n",
      "[104/200] - ptime: 160.58, loss_D_A: 0.068, loss_D_B: 0.123, loss_G_A: 0.787, loss_G_B: 0.512, loss_A_cycle: 1.153, loss_B_cycle: 0.563\n",
      "[105/200] - ptime: 160.26, loss_D_A: 0.056, loss_D_B: 0.116, loss_G_A: 0.769, loss_G_B: 0.522, loss_A_cycle: 1.150, loss_B_cycle: 0.557\n",
      "[106/200] - ptime: 160.27, loss_D_A: 0.060, loss_D_B: 0.114, loss_G_A: 0.818, loss_G_B: 0.541, loss_A_cycle: 1.176, loss_B_cycle: 0.576\n",
      "[107/200] - ptime: 160.59, loss_D_A: 0.056, loss_D_B: 0.118, loss_G_A: 0.803, loss_G_B: 0.558, loss_A_cycle: 1.153, loss_B_cycle: 0.578\n",
      "[108/200] - ptime: 160.28, loss_D_A: 0.051, loss_D_B: 0.114, loss_G_A: 0.816, loss_G_B: 0.529, loss_A_cycle: 1.173, loss_B_cycle: 0.556\n",
      "[109/200] - ptime: 160.28, loss_D_A: 0.057, loss_D_B: 0.118, loss_G_A: 0.793, loss_G_B: 0.510, loss_A_cycle: 1.122, loss_B_cycle: 0.558\n",
      "[110/200] - ptime: 160.10, loss_D_A: 0.056, loss_D_B: 0.121, loss_G_A: 0.793, loss_G_B: 0.528, loss_A_cycle: 1.116, loss_B_cycle: 0.572\n",
      "[111/200] - ptime: 160.45, loss_D_A: 0.058, loss_D_B: 0.110, loss_G_A: 0.792, loss_G_B: 0.518, loss_A_cycle: 1.154, loss_B_cycle: 0.565\n",
      "[112/200] - ptime: 164.16, loss_D_A: 0.051, loss_D_B: 0.115, loss_G_A: 0.802, loss_G_B: 0.544, loss_A_cycle: 1.131, loss_B_cycle: 0.563\n",
      "[113/200] - ptime: 160.56, loss_D_A: 0.056, loss_D_B: 0.117, loss_G_A: 0.788, loss_G_B: 0.522, loss_A_cycle: 1.129, loss_B_cycle: 0.572\n",
      "[114/200] - ptime: 162.71, loss_D_A: 0.054, loss_D_B: 0.093, loss_G_A: 0.792, loss_G_B: 0.607, loss_A_cycle: 1.175, loss_B_cycle: 0.615\n",
      "[115/200] - ptime: 160.41, loss_D_A: 0.054, loss_D_B: 0.094, loss_G_A: 0.804, loss_G_B: 0.586, loss_A_cycle: 1.155, loss_B_cycle: 0.582\n",
      "[116/200] - ptime: 160.38, loss_D_A: 0.052, loss_D_B: 0.103, loss_G_A: 0.805, loss_G_B: 0.557, loss_A_cycle: 1.113, loss_B_cycle: 0.554\n",
      "[117/200] - ptime: 160.06, loss_D_A: 0.055, loss_D_B: 0.106, loss_G_A: 0.811, loss_G_B: 0.532, loss_A_cycle: 1.083, loss_B_cycle: 0.545\n",
      "[118/200] - ptime: 160.48, loss_D_A: 0.050, loss_D_B: 0.105, loss_G_A: 0.840, loss_G_B: 0.554, loss_A_cycle: 1.128, loss_B_cycle: 0.568\n",
      "[119/200] - ptime: 160.67, loss_D_A: 0.052, loss_D_B: 0.105, loss_G_A: 0.796, loss_G_B: 0.539, loss_A_cycle: 1.089, loss_B_cycle: 0.542\n",
      "[120/200] - ptime: 160.29, loss_D_A: 0.053, loss_D_B: 0.105, loss_G_A: 0.802, loss_G_B: 0.546, loss_A_cycle: 1.082, loss_B_cycle: 0.544\n",
      "[121/200] - ptime: 159.96, loss_D_A: 0.050, loss_D_B: 0.102, loss_G_A: 0.835, loss_G_B: 0.534, loss_A_cycle: 1.112, loss_B_cycle: 0.553\n",
      "[122/200] - ptime: 160.62, loss_D_A: 0.044, loss_D_B: 0.100, loss_G_A: 0.845, loss_G_B: 0.556, loss_A_cycle: 1.125, loss_B_cycle: 0.566\n",
      "[123/200] - ptime: 161.07, loss_D_A: 0.041, loss_D_B: 0.107, loss_G_A: 0.828, loss_G_B: 0.531, loss_A_cycle: 1.113, loss_B_cycle: 0.538\n",
      "[124/200] - ptime: 160.27, loss_D_A: 0.057, loss_D_B: 0.111, loss_G_A: 0.783, loss_G_B: 0.545, loss_A_cycle: 1.078, loss_B_cycle: 0.536\n",
      "[125/200] - ptime: 160.17, loss_D_A: 0.046, loss_D_B: 0.106, loss_G_A: 0.808, loss_G_B: 0.528, loss_A_cycle: 1.067, loss_B_cycle: 0.531\n",
      "[126/200] - ptime: 160.49, loss_D_A: 0.044, loss_D_B: 0.101, loss_G_A: 0.852, loss_G_B: 0.562, loss_A_cycle: 1.061, loss_B_cycle: 0.545\n",
      "[127/200] - ptime: 160.39, loss_D_A: 0.049, loss_D_B: 0.106, loss_G_A: 0.786, loss_G_B: 0.527, loss_A_cycle: 1.083, loss_B_cycle: 0.526\n",
      "[128/200] - ptime: 160.29, loss_D_A: 0.047, loss_D_B: 0.111, loss_G_A: 0.814, loss_G_B: 0.554, loss_A_cycle: 1.048, loss_B_cycle: 0.526\n",
      "[129/200] - ptime: 160.27, loss_D_A: 0.049, loss_D_B: 0.101, loss_G_A: 0.809, loss_G_B: 0.559, loss_A_cycle: 1.018, loss_B_cycle: 0.537\n",
      "[130/200] - ptime: 160.19, loss_D_A: 0.044, loss_D_B: 0.107, loss_G_A: 0.830, loss_G_B: 0.525, loss_A_cycle: 1.052, loss_B_cycle: 0.535\n",
      "[131/200] - ptime: 159.98, loss_D_A: 0.048, loss_D_B: 0.105, loss_G_A: 0.823, loss_G_B: 0.563, loss_A_cycle: 1.040, loss_B_cycle: 0.534\n",
      "[132/200] - ptime: 160.51, loss_D_A: 0.046, loss_D_B: 0.104, loss_G_A: 0.812, loss_G_B: 0.572, loss_A_cycle: 1.021, loss_B_cycle: 0.536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[133/200] - ptime: 160.16, loss_D_A: 0.047, loss_D_B: 0.103, loss_G_A: 0.810, loss_G_B: 0.553, loss_A_cycle: 1.034, loss_B_cycle: 0.511\n",
      "[134/200] - ptime: 161.35, loss_D_A: 0.046, loss_D_B: 0.105, loss_G_A: 0.836, loss_G_B: 0.553, loss_A_cycle: 1.023, loss_B_cycle: 0.513\n",
      "[135/200] - ptime: 161.76, loss_D_A: 0.043, loss_D_B: 0.100, loss_G_A: 0.827, loss_G_B: 0.552, loss_A_cycle: 0.989, loss_B_cycle: 0.517\n",
      "[136/200] - ptime: 160.48, loss_D_A: 0.042, loss_D_B: 0.099, loss_G_A: 0.826, loss_G_B: 0.554, loss_A_cycle: 1.028, loss_B_cycle: 0.534\n",
      "[137/200] - ptime: 160.25, loss_D_A: 0.041, loss_D_B: 0.100, loss_G_A: 0.837, loss_G_B: 0.558, loss_A_cycle: 1.005, loss_B_cycle: 0.523\n",
      "[138/200] - ptime: 160.58, loss_D_A: 0.042, loss_D_B: 0.103, loss_G_A: 0.819, loss_G_B: 0.552, loss_A_cycle: 0.981, loss_B_cycle: 0.514\n",
      "[139/200] - ptime: 160.82, loss_D_A: 0.042, loss_D_B: 0.104, loss_G_A: 0.826, loss_G_B: 0.537, loss_A_cycle: 1.003, loss_B_cycle: 0.517\n",
      "[140/200] - ptime: 160.58, loss_D_A: 0.041, loss_D_B: 0.098, loss_G_A: 0.861, loss_G_B: 0.608, loss_A_cycle: 1.025, loss_B_cycle: 0.523\n",
      "[141/200] - ptime: 161.38, loss_D_A: 0.035, loss_D_B: 0.105, loss_G_A: 0.874, loss_G_B: 0.558, loss_A_cycle: 0.977, loss_B_cycle: 0.506\n",
      "[142/200] - ptime: 159.96, loss_D_A: 0.036, loss_D_B: 0.107, loss_G_A: 0.838, loss_G_B: 0.539, loss_A_cycle: 0.962, loss_B_cycle: 0.500\n",
      "[143/200] - ptime: 160.98, loss_D_A: 0.043, loss_D_B: 0.103, loss_G_A: 0.809, loss_G_B: 0.537, loss_A_cycle: 0.964, loss_B_cycle: 0.498\n",
      "[144/200] - ptime: 160.45, loss_D_A: 0.043, loss_D_B: 0.105, loss_G_A: 0.847, loss_G_B: 0.528, loss_A_cycle: 0.952, loss_B_cycle: 0.496\n",
      "[145/200] - ptime: 159.98, loss_D_A: 0.038, loss_D_B: 0.101, loss_G_A: 0.850, loss_G_B: 0.576, loss_A_cycle: 0.962, loss_B_cycle: 0.507\n",
      "[146/200] - ptime: 160.17, loss_D_A: 0.038, loss_D_B: 0.104, loss_G_A: 0.829, loss_G_B: 0.551, loss_A_cycle: 0.988, loss_B_cycle: 0.495\n",
      "[147/200] - ptime: 160.46, loss_D_A: 0.037, loss_D_B: 0.101, loss_G_A: 0.841, loss_G_B: 0.530, loss_A_cycle: 0.963, loss_B_cycle: 0.492\n",
      "[148/200] - ptime: 160.20, loss_D_A: 0.039, loss_D_B: 0.105, loss_G_A: 0.828, loss_G_B: 0.540, loss_A_cycle: 0.995, loss_B_cycle: 0.503\n",
      "[149/200] - ptime: 159.99, loss_D_A: 0.040, loss_D_B: 0.100, loss_G_A: 0.838, loss_G_B: 0.576, loss_A_cycle: 0.959, loss_B_cycle: 0.491\n",
      "[150/200] - ptime: 159.90, loss_D_A: 0.036, loss_D_B: 0.098, loss_G_A: 0.860, loss_G_B: 0.564, loss_A_cycle: 0.916, loss_B_cycle: 0.485\n",
      "[151/200] - ptime: 159.86, loss_D_A: 0.037, loss_D_B: 0.096, loss_G_A: 0.848, loss_G_B: 0.565, loss_A_cycle: 0.934, loss_B_cycle: 0.484\n",
      "[152/200] - ptime: 160.17, loss_D_A: 0.036, loss_D_B: 0.094, loss_G_A: 0.861, loss_G_B: 0.572, loss_A_cycle: 0.947, loss_B_cycle: 0.494\n",
      "[153/200] - ptime: 159.89, loss_D_A: 0.036, loss_D_B: 0.094, loss_G_A: 0.865, loss_G_B: 0.570, loss_A_cycle: 0.926, loss_B_cycle: 0.494\n",
      "[154/200] - ptime: 159.55, loss_D_A: 0.032, loss_D_B: 0.101, loss_G_A: 0.890, loss_G_B: 0.554, loss_A_cycle: 0.898, loss_B_cycle: 0.482\n",
      "[155/200] - ptime: 159.91, loss_D_A: 0.023, loss_D_B: 0.106, loss_G_A: 0.905, loss_G_B: 0.545, loss_A_cycle: 0.888, loss_B_cycle: 0.473\n",
      "[156/200] - ptime: 159.56, loss_D_A: 0.026, loss_D_B: 0.097, loss_G_A: 0.890, loss_G_B: 0.554, loss_A_cycle: 0.909, loss_B_cycle: 0.483\n",
      "[157/200] - ptime: 159.69, loss_D_A: 0.041, loss_D_B: 0.096, loss_G_A: 0.812, loss_G_B: 0.566, loss_A_cycle: 0.906, loss_B_cycle: 0.494\n",
      "[158/200] - ptime: 160.09, loss_D_A: 0.036, loss_D_B: 0.093, loss_G_A: 0.835, loss_G_B: 0.572, loss_A_cycle: 0.907, loss_B_cycle: 0.485\n",
      "[159/200] - ptime: 159.59, loss_D_A: 0.035, loss_D_B: 0.095, loss_G_A: 0.835, loss_G_B: 0.589, loss_A_cycle: 0.895, loss_B_cycle: 0.472\n",
      "[160/200] - ptime: 159.48, loss_D_A: 0.037, loss_D_B: 0.096, loss_G_A: 0.847, loss_G_B: 0.559, loss_A_cycle: 0.927, loss_B_cycle: 0.470\n",
      "[161/200] - ptime: 159.69, loss_D_A: 0.033, loss_D_B: 0.094, loss_G_A: 0.866, loss_G_B: 0.592, loss_A_cycle: 0.912, loss_B_cycle: 0.480\n",
      "[162/200] - ptime: 160.28, loss_D_A: 0.037, loss_D_B: 0.092, loss_G_A: 0.847, loss_G_B: 0.603, loss_A_cycle: 0.895, loss_B_cycle: 0.493\n",
      "[163/200] - ptime: 160.06, loss_D_A: 0.033, loss_D_B: 0.098, loss_G_A: 0.848, loss_G_B: 0.557, loss_A_cycle: 0.910, loss_B_cycle: 0.478\n",
      "[164/200] - ptime: 160.08, loss_D_A: 0.034, loss_D_B: 0.095, loss_G_A: 0.840, loss_G_B: 0.575, loss_A_cycle: 0.887, loss_B_cycle: 0.469\n",
      "[165/200] - ptime: 159.90, loss_D_A: 0.033, loss_D_B: 0.097, loss_G_A: 0.872, loss_G_B: 0.570, loss_A_cycle: 0.906, loss_B_cycle: 0.471\n",
      "[166/200] - ptime: 159.95, loss_D_A: 0.032, loss_D_B: 0.098, loss_G_A: 0.872, loss_G_B: 0.556, loss_A_cycle: 0.876, loss_B_cycle: 0.465\n",
      "[167/200] - ptime: 159.58, loss_D_A: 0.034, loss_D_B: 0.091, loss_G_A: 0.857, loss_G_B: 0.568, loss_A_cycle: 0.850, loss_B_cycle: 0.466\n",
      "[168/200] - ptime: 160.38, loss_D_A: 0.031, loss_D_B: 0.093, loss_G_A: 0.885, loss_G_B: 0.575, loss_A_cycle: 0.850, loss_B_cycle: 0.463\n",
      "[169/200] - ptime: 159.89, loss_D_A: 0.030, loss_D_B: 0.095, loss_G_A: 0.884, loss_G_B: 0.571, loss_A_cycle: 0.859, loss_B_cycle: 0.456\n",
      "[170/200] - ptime: 160.06, loss_D_A: 0.031, loss_D_B: 0.093, loss_G_A: 0.881, loss_G_B: 0.592, loss_A_cycle: 0.860, loss_B_cycle: 0.460\n",
      "[171/200] - ptime: 159.77, loss_D_A: 0.030, loss_D_B: 0.093, loss_G_A: 0.891, loss_G_B: 0.577, loss_A_cycle: 0.857, loss_B_cycle: 0.455\n",
      "[172/200] - ptime: 160.08, loss_D_A: 0.030, loss_D_B: 0.094, loss_G_A: 0.877, loss_G_B: 0.577, loss_A_cycle: 0.853, loss_B_cycle: 0.460\n",
      "[173/200] - ptime: 159.87, loss_D_A: 0.031, loss_D_B: 0.092, loss_G_A: 0.873, loss_G_B: 0.566, loss_A_cycle: 0.843, loss_B_cycle: 0.458\n",
      "[174/200] - ptime: 160.39, loss_D_A: 0.030, loss_D_B: 0.092, loss_G_A: 0.874, loss_G_B: 0.576, loss_A_cycle: 0.823, loss_B_cycle: 0.446\n",
      "[175/200] - ptime: 159.97, loss_D_A: 0.029, loss_D_B: 0.093, loss_G_A: 0.891, loss_G_B: 0.573, loss_A_cycle: 0.835, loss_B_cycle: 0.448\n",
      "[176/200] - ptime: 159.37, loss_D_A: 0.029, loss_D_B: 0.092, loss_G_A: 0.873, loss_G_B: 0.585, loss_A_cycle: 0.842, loss_B_cycle: 0.446\n",
      "[177/200] - ptime: 159.98, loss_D_A: 0.027, loss_D_B: 0.091, loss_G_A: 0.899, loss_G_B: 0.649, loss_A_cycle: 0.848, loss_B_cycle: 0.454\n",
      "[178/200] - ptime: 159.78, loss_D_A: 0.029, loss_D_B: 0.085, loss_G_A: 0.892, loss_G_B: 0.593, loss_A_cycle: 0.827, loss_B_cycle: 0.454\n",
      "[179/200] - ptime: 160.19, loss_D_A: 0.028, loss_D_B: 0.091, loss_G_A: 0.891, loss_G_B: 0.553, loss_A_cycle: 0.820, loss_B_cycle: 0.443\n",
      "[180/200] - ptime: 159.92, loss_D_A: 0.029, loss_D_B: 0.094, loss_G_A: 0.893, loss_G_B: 0.573, loss_A_cycle: 0.813, loss_B_cycle: 0.441\n",
      "[181/200] - ptime: 160.09, loss_D_A: 0.027, loss_D_B: 0.095, loss_G_A: 0.903, loss_G_B: 0.576, loss_A_cycle: 0.830, loss_B_cycle: 0.442\n",
      "[182/200] - ptime: 160.27, loss_D_A: 0.028, loss_D_B: 0.095, loss_G_A: 0.897, loss_G_B: 0.585, loss_A_cycle: 0.843, loss_B_cycle: 0.446\n",
      "[183/200] - ptime: 160.16, loss_D_A: 0.026, loss_D_B: 0.089, loss_G_A: 0.897, loss_G_B: 0.637, loss_A_cycle: 0.839, loss_B_cycle: 0.437\n",
      "[184/200] - ptime: 160.68, loss_D_A: 0.026, loss_D_B: 0.088, loss_G_A: 0.908, loss_G_B: 0.575, loss_A_cycle: 0.815, loss_B_cycle: 0.438\n",
      "[185/200] - ptime: 159.97, loss_D_A: 0.025, loss_D_B: 0.090, loss_G_A: 0.910, loss_G_B: 0.603, loss_A_cycle: 0.798, loss_B_cycle: 0.436\n",
      "[186/200] - ptime: 160.28, loss_D_A: 0.025, loss_D_B: 0.089, loss_G_A: 0.899, loss_G_B: 0.600, loss_A_cycle: 0.807, loss_B_cycle: 0.437\n",
      "[187/200] - ptime: 160.07, loss_D_A: 0.025, loss_D_B: 0.092, loss_G_A: 0.905, loss_G_B: 0.596, loss_A_cycle: 0.793, loss_B_cycle: 0.433\n",
      "[188/200] - ptime: 160.29, loss_D_A: 0.024, loss_D_B: 0.090, loss_G_A: 0.904, loss_G_B: 0.611, loss_A_cycle: 0.788, loss_B_cycle: 0.434\n",
      "[189/200] - ptime: 160.42, loss_D_A: 0.024, loss_D_B: 0.092, loss_G_A: 0.900, loss_G_B: 0.623, loss_A_cycle: 0.797, loss_B_cycle: 0.434\n",
      "[190/200] - ptime: 160.48, loss_D_A: 0.024, loss_D_B: 0.090, loss_G_A: 0.920, loss_G_B: 0.613, loss_A_cycle: 0.788, loss_B_cycle: 0.428\n",
      "[191/200] - ptime: 159.98, loss_D_A: 0.024, loss_D_B: 0.085, loss_G_A: 0.917, loss_G_B: 0.626, loss_A_cycle: 0.797, loss_B_cycle: 0.428\n",
      "[192/200] - ptime: 160.10, loss_D_A: 0.024, loss_D_B: 0.088, loss_G_A: 0.897, loss_G_B: 0.623, loss_A_cycle: 0.790, loss_B_cycle: 0.428\n",
      "[193/200] - ptime: 160.68, loss_D_A: 0.023, loss_D_B: 0.090, loss_G_A: 0.918, loss_G_B: 0.607, loss_A_cycle: 0.784, loss_B_cycle: 0.421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[194/200] - ptime: 159.98, loss_D_A: 0.022, loss_D_B: 0.090, loss_G_A: 0.924, loss_G_B: 0.616, loss_A_cycle: 0.771, loss_B_cycle: 0.425\n",
      "[195/200] - ptime: 160.08, loss_D_A: 0.022, loss_D_B: 0.088, loss_G_A: 0.924, loss_G_B: 0.634, loss_A_cycle: 0.772, loss_B_cycle: 0.417\n",
      "[196/200] - ptime: 160.10, loss_D_A: 0.022, loss_D_B: 0.091, loss_G_A: 0.910, loss_G_B: 0.637, loss_A_cycle: 0.763, loss_B_cycle: 0.425\n",
      "[197/200] - ptime: 160.09, loss_D_A: 0.022, loss_D_B: 0.092, loss_G_A: 0.922, loss_G_B: 0.631, loss_A_cycle: 0.766, loss_B_cycle: 0.421\n",
      "[198/200] - ptime: 160.31, loss_D_A: 0.022, loss_D_B: 0.090, loss_G_A: 0.927, loss_G_B: 0.648, loss_A_cycle: 0.771, loss_B_cycle: 0.416\n",
      "[199/200] - ptime: 160.17, loss_D_A: 0.021, loss_D_B: 0.093, loss_G_A: 0.920, loss_G_B: 0.638, loss_A_cycle: 0.760, loss_B_cycle: 0.411\n",
      "[200/200] - ptime: 160.26, loss_D_A: 0.019, loss_D_B: 0.090, loss_G_A: 0.919, loss_G_B: 0.628, loss_A_cycle: 0.764, loss_B_cycle: 0.415\n"
     ]
    }
   ],
   "source": [
    "print('**************************start training!**************************')\n",
    "start_time = time.time()\n",
    "for epoch in range(opt.train_epoch):\n",
    "    D_A_losses = []\n",
    "    D_B_losses = []\n",
    "    G_A_losses = []\n",
    "    G_B_losses = []\n",
    "    A_cycle_losses = []\n",
    "    B_cycle_losses = []\n",
    "    epoch_start_time = time.time()\n",
    "    num_iter = 0\n",
    "    if (epoch+1) > opt.decay_epoch:\n",
    "        D_A_optimizer.param_groups[0]['lr'] -= opt.lrD / (opt.train_epoch - opt.decay_epoch)\n",
    "        D_B_optimizer.param_groups[0]['lr'] -= opt.lrD / (opt.train_epoch - opt.decay_epoch)\n",
    "        G_optimizer.param_groups[0]['lr'] -= opt.lrG / (opt.train_epoch - opt.decay_epoch)\n",
    "\n",
    "    for (realA, _), (realB, _) in zip(train_loader_A, train_loader_B):\n",
    "        if opt.resize_scale:\n",
    "            realA = utils.imgs_resize(realA, opt.resize_scale)\n",
    "            realB = utils.imgs_resize(realB, opt.resize_scale)\n",
    "\n",
    "        if opt.crop:\n",
    "            realA = utils.random_crop(realA, opt.input_size)\n",
    "            realB = utils.random_crop(realB, opt.input_size)\n",
    "\n",
    "        if opt.fliplr:\n",
    "            realA = utils.random_fliplr(realA)\n",
    "            realB = utils.random_fliplr(realB)\n",
    "\n",
    "        realA, realB = Variable(realA.cuda()), Variable(realB.cuda())\n",
    "\n",
    "        # train generator G\n",
    "        G_optimizer.zero_grad()\n",
    "\n",
    "        # generate real A to fake B; D_A(G_A(A))\n",
    "        fakeB = G_A(realA)\n",
    "        D_A_result = D_A(fakeB)\n",
    "        G_A_loss = MSE_loss(D_A_result, Variable(torch.ones(D_A_result.size()).cuda()))\n",
    "\n",
    "        # reconstruct fake B to rec A; G_B(G_A(A))\n",
    "        recA = G_B(fakeB)\n",
    "        A_cycle_loss = L1_loss(recA, realA) * opt.lambdaA\n",
    "\n",
    "        # generate real B to fake A; D_A(G_B(B))\n",
    "        fakeA = G_B(realB)\n",
    "        D_B_result = D_B(fakeA)\n",
    "        G_B_loss = MSE_loss(D_B_result, Variable(torch.ones(D_B_result.size()).cuda()))\n",
    "\n",
    "        # reconstruct fake A to rec B G_A(G_B(B))\n",
    "        recB = G_A(fakeA)\n",
    "        B_cycle_loss = L1_loss(recB, realB) * opt.lambdaB\n",
    "\n",
    "        G_loss = G_A_loss + G_B_loss + A_cycle_loss + B_cycle_loss\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "\n",
    "        train_hist['G_A_losses'].append(G_A_loss.data)\n",
    "        train_hist['G_B_losses'].append(G_B_loss.data)\n",
    "        train_hist['A_cycle_losses'].append(A_cycle_loss.data)\n",
    "        train_hist['B_cycle_losses'].append(B_cycle_loss.data)\n",
    "\n",
    "        G_A_losses.append(G_A_loss.data)\n",
    "        G_B_losses.append(G_B_loss.data)\n",
    "        A_cycle_losses.append(A_cycle_loss.data)\n",
    "        B_cycle_losses.append(B_cycle_loss.data)\n",
    "\n",
    "        # train discriminator D_A\n",
    "        D_A_optimizer.zero_grad()\n",
    "\n",
    "        D_A_real = D_A(realB)\n",
    "        D_A_real_loss = MSE_loss(D_A_real, Variable(torch.ones(D_A_real.size()).cuda()))\n",
    "\n",
    "        # fakeB = fakeB_store.query(fakeB.data)\n",
    "        fakeB = fakeB_store.query(fakeB)\n",
    "        D_A_fake = D_A(fakeB)\n",
    "        D_A_fake_loss = MSE_loss(D_A_fake, Variable(torch.zeros(D_A_fake.size()).cuda()))\n",
    "\n",
    "        D_A_loss = (D_A_real_loss + D_A_fake_loss) * 0.5\n",
    "        D_A_loss.backward()\n",
    "        D_A_optimizer.step()\n",
    "\n",
    "        train_hist['D_A_losses'].append(D_A_loss.data)\n",
    "        D_A_losses.append(D_A_loss.data)\n",
    "\n",
    "        # train discriminator D_B\n",
    "        D_B_optimizer.zero_grad()\n",
    "\n",
    "        D_B_real = D_B(realA)\n",
    "        D_B_real_loss = MSE_loss(D_B_real, Variable(torch.ones(D_B_real.size()).cuda()))\n",
    "\n",
    "        # fakeA = fakeA_store.query(fakeA.data)\n",
    "        fakeA = fakeA_store.query(fakeA)\n",
    "        D_B_fake = D_B(fakeA)\n",
    "        D_B_fake_loss = MSE_loss(D_B_fake, Variable(torch.zeros(D_B_fake.size()).cuda()))\n",
    "\n",
    "        D_B_loss = (D_B_real_loss + D_B_fake_loss) * 0.5\n",
    "        D_B_loss.backward()\n",
    "        D_B_optimizer.step()\n",
    "\n",
    "        train_hist['D_B_losses'].append(D_B_loss.data)\n",
    "        D_B_losses.append(D_B_loss.data)\n",
    "\n",
    "        num_iter += 1\n",
    "\n",
    "    epoch_end_time = time.time()\n",
    "    per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "    train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "    print(\n",
    "    '[%d/%d] - ptime: %.2f, loss_D_A: %.3f, loss_D_B: %.3f, loss_G_A: %.3f, loss_G_B: %.3f, loss_A_cycle: %.3f, loss_B_cycle: %.3f' % (\n",
    "        (epoch + 1), opt.train_epoch, per_epoch_ptime, torch.mean(torch.FloatTensor(D_A_losses)),\n",
    "        torch.mean(torch.FloatTensor(D_B_losses)), torch.mean(torch.FloatTensor(G_A_losses)),\n",
    "        torch.mean(torch.FloatTensor(G_B_losses)), torch.mean(torch.FloatTensor(A_cycle_losses)),\n",
    "        torch.mean(torch.FloatTensor(B_cycle_losses))))\n",
    "\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        test.test_results_network(test_loader_A, test_loader_B, G_A, G_B, opt.dataset)\n",
    "    else:\n",
    "        train.train_results_network(train_loader_A, train_loader_B, G_A, G_B, opt.dataset)\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "train_hist['total_time'].append(total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg one epoch passing time: 160.20, total 200 epochs passing time: 39036.69\n",
      "Training finish!... save training results\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg one epoch passing time: %.2f, total %d epochs passing time: %.2f\" % (torch.mean(torch.FloatTensor(train_hist['per_epoch_ptimes'])), opt.train_epoch, total_time))\n",
    "print(\"Training finish!... save training results\")\n",
    "torch.save(G_A.state_dict(), root + model + 'generatorA_param.pkl')\n",
    "torch.save(G_B.state_dict(), root + model + 'generatorB_param.pkl')\n",
    "torch.save(D_A.state_dict(), root + model + 'discriminatorA_param.pkl')\n",
    "torch.save(D_B.state_dict(), root + model + 'discriminatorB_param.pkl')\n",
    "with open(root + model + 'train_hist.pkl', 'wb') as f:\n",
    "    pickle.dump(train_hist, f)\n",
    "\n",
    "utils.show_train_hist(train_hist, save=True, path=root + model + 'train_hist.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
